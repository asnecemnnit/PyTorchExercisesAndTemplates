{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleRNN(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, rnn_type=\"rnn\"):\n",
    "        super(FlexibleRNN, self).__init__()\n",
    "\n",
    "        # Choose the RNN cell type\n",
    "        if rnn_type.lower() == \"rnn\":\n",
    "            self.rnn = tf.keras.layers.SimpleRNN(\n",
    "                hidden_size, return_sequences=True, return_state=True\n",
    "            )\n",
    "        elif rnn_type.lower() == \"lstm\":\n",
    "            self.rnn = tf.keras.layers.LSTM(\n",
    "                hidden_size, return_sequences=True, return_state=True\n",
    "            )\n",
    "        elif rnn_type.lower() == \"gru\":\n",
    "            self.rnn = tf.keras.layers.GRU(\n",
    "                hidden_size, return_sequences=True, return_state=True\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid rnn_type. Choose 'rnn', 'lstm', 'gru'\")\n",
    "\n",
    "        # Fully connected layer to map RNN output to the desired output size\n",
    "        self.fc = tf.keras.layers.Dense(output_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # RNN forward pass\n",
    "        rnn_out = self.rnn(inputs)\n",
    "\n",
    "        if len(rnn_out) == 3:\n",
    "            # LSTM case\n",
    "            whole_sequence_output, _, _ = rnn_out\n",
    "        else:\n",
    "            # SimpleRNN/GRU case\n",
    "            whole_sequence_output, _ = rnn_out\n",
    "\n",
    "        # Extract the output from the last time step\n",
    "        last_output = whole_sequence_output[:, -1, :]\n",
    "\n",
    "        # Fully connected layer\n",
    "        output = self.fc(last_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def train_model(\n",
    "        self, train_data, train_labels, num_epochs=300, learning_rate=0.001\n",
    "    ):\n",
    "        # Define loss function and optimizer\n",
    "        criterion = tf.keras.losses.MeanSquaredError()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            with tf.GradientTape() as tape:\n",
    "                outputs = self(train_data)\n",
    "                loss = criterion(train_labels, outputs)\n",
    "\n",
    "            # Backward and optimize\n",
    "            gradients = tape.gradient(loss, self.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        # Make predictions for input_data\n",
    "        predictions = self(input_data)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(tf.keras.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_heads=2, num_layers=2):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        self.embedding = Dense(hidden_size, activation='relu')\n",
    "        \n",
    "        self.attention_blocks = [Attention(use_scale=True) for _ in range(num_layers)]\n",
    "        \n",
    "        self.fc = Dense(output_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply embedding layer\n",
    "        x = self.embedding(inputs)\n",
    "\n",
    "        # Transformer blocks\n",
    "        for attention_block in self.attention_blocks:\n",
    "            x = attention_block([x, x])\n",
    "\n",
    "        # Global average pooling\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        output = self.fc(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def train_model(self, train_data, train_labels, num_epochs=300, learning_rate=0.001):\n",
    "        # Define loss function and optimizer\n",
    "        criterion = tf.keras.losses.MeanSquaredError()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            with tf.GradientTape() as tape:\n",
    "                outputs = self(train_data)\n",
    "                loss = criterion(train_labels, outputs)\n",
    "\n",
    "            # Backward and optimize\n",
    "            gradients = tape.gradient(loss, self.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.numpy():.4f}')\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        # Make predictions for input_data\n",
    "        predictions = self(input_data)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (RNNs for sequence processing):\n",
    "# Define input size, hidden size, and output size\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "\n",
    "# Create an instance of the FlexibleRNN model with Generic RNN\n",
    "model = FlexibleRNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Create an instance of the FlexibleRNN model with LSTM\n",
    "model_lstm = FlexibleRNN(input_size, hidden_size, output_size, rnn_type=\"lstm\")\n",
    "\n",
    "# Create an instance of the FlexibleRNN model with GRU\n",
    "model_gru = FlexibleRNN(input_size, hidden_size, output_size, rnn_type=\"gru\")\n",
    "\n",
    "# Generate synthetic training data\n",
    "train_data = tf.random.normal((100, 8, input_size))\n",
    "train_labels = tf.random.normal((100, output_size))\n",
    "\n",
    "# Train the RNN model\n",
    "model.train_model(train_data, train_labels)\n",
    "\n",
    "# Train the LSTM model\n",
    "model_lstm.train_model(train_data, train_labels)\n",
    "\n",
    "# Train the GRU model\n",
    "model_gru.train_model(train_data, train_labels)\n",
    "\n",
    "# Generate a test sequence\n",
    "test_data = tf.random.normal((1, 8, input_size))\n",
    "\n",
    "# Make predictions with Generic RNN model\n",
    "predictions = model.predict(test_data)\n",
    "print(\"Predictions:\", predictions.numpy())\n",
    "\n",
    "# Make predictions with LSTM model\n",
    "predictions_lstm = model_lstm.predict(test_data)\n",
    "print(\"Predictions (LSTM):\", predictions_lstm.numpy())\n",
    "\n",
    "# Make predictions with GRU model\n",
    "predictions_gru = model_gru.predict(test_data)\n",
    "print(\"Predictions (GRU):\", predictions_gru.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (transformer for sequence processing):\n",
    "# Define input size, hidden size, and output size\n",
    "input_size = 10\n",
    "hidden_size = 32\n",
    "output_size = 5\n",
    "\n",
    "# Create an instance of the TransformerModel\n",
    "model_transformer = TransformerModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Generate synthetic training data\n",
    "train_data = tf.random.normal((100, 8, input_size))\n",
    "train_labels = tf.random.normal((100, output_size))\n",
    "\n",
    "# Train the Transformer model\n",
    "model_transformer.train_model(train_data, train_labels)\n",
    "\n",
    "# Generate a test sequence\n",
    "test_data = tf.random.normal((1, 8, input_size))\n",
    "\n",
    "# Make predictions with Transformer model\n",
    "predictions_transformer = model_transformer.predict(test_data)\n",
    "print(\"Predictions (Transformer):\", predictions_transformer.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ValeoML)",
   "language": "python",
   "name": "valeoml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
